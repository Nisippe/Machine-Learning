1)Loading the dataset
  -Importare Librerie
  -Caricare data set
  -Encoding / NaN values

2)Summarizing the dataset
  -Dimensione del dataset (dataset.shape)
  -Guardare i dati (dataset.head())
  -Riassunto statistico di tutti gli attributi (dataset.describe())
  -Distribuzione delle classi (dataset.groupby('class').size())

3)Visualizing the dataset
  -Univariable Plots
    (dataset.plot(kind='box', subplots=True, layout=(2,2),
      sharex=False, sharey=False)
      pyplot.show()) per istogrammi (dataset.hist() pyplot.show())

   -MultiVariate Plots (scatter_matrix(dataset) pyplot.show())

4)Evaluating some algorithms.
  -Dataset validation
  (array = dataset.values
      X = array[:,0:4]
      y = array[:,4]
      X_train, X_validation, Y_train, Y_validation =
      train_test_split(X, y, test_size=0.20, random_state=1))

  -Test Harness
  -Build Models
  (Logistic Regression (LR)
    Linear Discriminant Analysis (LDA)
    K-Nearest Neighbors (KNN).
    Classification and Regression Trees (CART).
    Gaussian Naive Bayes (NB).
    Support Vector Machines (SVM).)

  -Select Best Model

5)Making some predictions.
  -Make Predictions
  (model = SVC(gamma='auto')
    model.fit(X_train, Y_train)
    predictions = model.predict(X_validation))

  -Evaluate Predictions
  (print(accuracy_score(Y_validation, predictions))
    print(confusion_matrix(Y_validation, predictions))
    print(classification_report(Y_validation, predictions)))
